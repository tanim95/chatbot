{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpMcwhY7-WUX"
      },
      "source": [
        "#chatbots\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "eEGdOnrb8F3e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "vleNrqhN-V4u"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/train_qa.txt','rb') as f:\n",
        "  train_data = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "ReXP4Yen-WB4"
      },
      "outputs": [],
      "source": [
        "with open('/content/test_qa.txt','rb') as f:\n",
        "  test_data = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "zxNclu4yA3Cx"
      },
      "outputs": [],
      "source": [
        "all_data  = train_data + test_data\n",
        "# all_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GLDyiJdg-WDi",
        "outputId": "0da2efcd-62d7-4075-aca6-ec22bd81b611"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 190
        }
      ],
      "source": [
        "' '.join(train_data[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eMlGJVjJAYSY",
        "outputId": "a15903a2-7a55-4477-d2b9-2f7e1c8027c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Is Sandra in the hallway ?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 191
        }
      ],
      "source": [
        "' '.join(train_data[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PZvEaXi5BE2v",
        "outputId": "aabfb7b6-1e6e-4e4c-f7dc-9c65db33397b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'n o'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 192
        }
      ],
      "source": [
        "' '.join(train_data[0][2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5Ujdrn51BIgU",
        "outputId": "1027ff16-7261-4f38-bf09-05d2b4c14935"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Story  \\\n",
              "0      [Mary, moved, to, the, bathroom, ., Sandra, jo...   \n",
              "1      [Mary, moved, to, the, bathroom, ., Sandra, jo...   \n",
              "2      [Mary, moved, to, the, bathroom, ., Sandra, jo...   \n",
              "3      [Mary, moved, to, the, bathroom, ., Sandra, jo...   \n",
              "4      [Mary, moved, to, the, bathroom, ., Sandra, jo...   \n",
              "...                                                  ...   \n",
              "10995  [Mary, moved, to, the, kitchen, ., Mary, trave...   \n",
              "10996  [Mary, moved, to, the, kitchen, ., Mary, trave...   \n",
              "10997  [Mary, moved, to, the, kitchen, ., Mary, trave...   \n",
              "10998  [Mary, moved, to, the, kitchen, ., Mary, trave...   \n",
              "10999  [Mary, moved, to, the, kitchen, ., Mary, trave...   \n",
              "\n",
              "                                 Question Answer  \n",
              "0       [Is, Sandra, in, the, hallway, ?]     no  \n",
              "1      [Is, Daniel, in, the, bathroom, ?]     no  \n",
              "2        [Is, Daniel, in, the, office, ?]     no  \n",
              "3       [Is, Daniel, in, the, bedroom, ?]    yes  \n",
              "4       [Is, Daniel, in, the, bedroom, ?]    yes  \n",
              "...                                   ...    ...  \n",
              "10995     [Is, Mary, in, the, bedroom, ?]     no  \n",
              "10996   [Is, Sandra, in, the, kitchen, ?]     no  \n",
              "10997     [Is, Mary, in, the, bedroom, ?]     no  \n",
              "10998    [Is, Sandra, in, the, garden, ?]    yes  \n",
              "10999      [Is, Mary, in, the, garden, ?]    yes  \n",
              "\n",
              "[11000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8095228-f2fe-4dfa-ae4e-d53d7d8b69fd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Story</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Mary, moved, to, the, bathroom, ., Sandra, jo...</td>\n",
              "      <td>[Is, Sandra, in, the, hallway, ?]</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Mary, moved, to, the, bathroom, ., Sandra, jo...</td>\n",
              "      <td>[Is, Daniel, in, the, bathroom, ?]</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Mary, moved, to, the, bathroom, ., Sandra, jo...</td>\n",
              "      <td>[Is, Daniel, in, the, office, ?]</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Mary, moved, to, the, bathroom, ., Sandra, jo...</td>\n",
              "      <td>[Is, Daniel, in, the, bedroom, ?]</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Mary, moved, to, the, bathroom, ., Sandra, jo...</td>\n",
              "      <td>[Is, Daniel, in, the, bedroom, ?]</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10995</th>\n",
              "      <td>[Mary, moved, to, the, kitchen, ., Mary, trave...</td>\n",
              "      <td>[Is, Mary, in, the, bedroom, ?]</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10996</th>\n",
              "      <td>[Mary, moved, to, the, kitchen, ., Mary, trave...</td>\n",
              "      <td>[Is, Sandra, in, the, kitchen, ?]</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10997</th>\n",
              "      <td>[Mary, moved, to, the, kitchen, ., Mary, trave...</td>\n",
              "      <td>[Is, Mary, in, the, bedroom, ?]</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10998</th>\n",
              "      <td>[Mary, moved, to, the, kitchen, ., Mary, trave...</td>\n",
              "      <td>[Is, Sandra, in, the, garden, ?]</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10999</th>\n",
              "      <td>[Mary, moved, to, the, kitchen, ., Mary, trave...</td>\n",
              "      <td>[Is, Mary, in, the, garden, ?]</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11000 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8095228-f2fe-4dfa-ae4e-d53d7d8b69fd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d8095228-f2fe-4dfa-ae4e-d53d7d8b69fd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d8095228-f2fe-4dfa-ae4e-d53d7d8b69fd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ecabd37c-5bf0-4309-a7a7-b4c5dba4b9c6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ecabd37c-5bf0-4309-a7a7-b4c5dba4b9c6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ecabd37c-5bf0-4309-a7a7-b4c5dba4b9c6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_668204ea-98a7-4474-a146-a439378eb39c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_668204ea-98a7-4474-a146-a439378eb39c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ],
      "source": [
        "df  = pd.DataFrame(all_data,columns=['Story','Question','Answer'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "A3hiu6p0BiMA"
      },
      "outputs": [],
      "source": [
        "vocab = set()\n",
        "for story,question,answer in all_data:\n",
        "  vocab = vocab.union(set(story))\n",
        "  vocab = vocab.union(set(question))\n",
        "vocab.add('yes')\n",
        "vocab.add('no')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "B5WybNS8Ds84",
        "outputId": "552d5385-8b4c-477f-e066-10ecf5eaf33f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0  1     2     3     4    5   6          7     8       9   ...  27  \\\n",
              "0  Daniel  .  went  Mary  left  yes  no  travelled  down  garden  ...  in   \n",
              "\n",
              "          28     29       30         31       32      33  34        35      36  \n",
              "0  discarded  there  dropped  journeyed  hallway  office  to  bathroom  Sandra  \n",
              "\n",
              "[1 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a758cf56-0e1b-4d80-8a93-8e4935bd65c6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Daniel</td>\n",
              "      <td>.</td>\n",
              "      <td>went</td>\n",
              "      <td>Mary</td>\n",
              "      <td>left</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>travelled</td>\n",
              "      <td>down</td>\n",
              "      <td>garden</td>\n",
              "      <td>...</td>\n",
              "      <td>in</td>\n",
              "      <td>discarded</td>\n",
              "      <td>there</td>\n",
              "      <td>dropped</td>\n",
              "      <td>journeyed</td>\n",
              "      <td>hallway</td>\n",
              "      <td>office</td>\n",
              "      <td>to</td>\n",
              "      <td>bathroom</td>\n",
              "      <td>Sandra</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 37 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a758cf56-0e1b-4d80-8a93-8e4935bd65c6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a758cf56-0e1b-4d80-8a93-8e4935bd65c6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a758cf56-0e1b-4d80-8a93-8e4935bd65c6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ],
      "source": [
        "pd.DataFrame(vocab).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "LtuEyeWNEQnc"
      },
      "outputs": [],
      "source": [
        "vocab_len = len(vocab) + 1\n",
        "# for i in range(len(all_data)):\n",
        "#   for data in all_data[i]:\n",
        "#     print(' '.join(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "4T5Ig79jEc5r"
      },
      "outputs": [],
      "source": [
        "stories_len = [len(data[0]) for data in all_data]\n",
        "question_len = [len(data[1]) for data in all_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiznzZJsEc8V",
        "outputId": "83182b94-f325-4985-a7a1-b3f3dbb797ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ],
      "source": [
        "maxlen_stories = max(stories_len)\n",
        "maxlen_stories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkVXNr6-Ec_G",
        "outputId": "17d9dde6-3a68-4b79-8c06-84acf34060fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ],
      "source": [
        "maxlen_question = max(question_len)\n",
        "maxlen_question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "wVt9sbYCDxDd"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(filters='!\"#$%&()*+-/:;<=>@[\\\\]^_`{|}~')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "915cDs9hOyEk"
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbziwTUUPFV0",
        "outputId": "df33f84f-0c22-499e-bd97-3bb513480558"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'daniel': 1,\n",
              " '.': 2,\n",
              " 'went': 3,\n",
              " 'mary': 4,\n",
              " 'left': 5,\n",
              " 'yes': 6,\n",
              " 'no': 7,\n",
              " 'travelled': 8,\n",
              " 'down': 9,\n",
              " 'garden': 10,\n",
              " 'grabbed': 11,\n",
              " 'kitchen': 12,\n",
              " 'put': 13,\n",
              " 'football': 14,\n",
              " 'took': 15,\n",
              " 'moved': 16,\n",
              " 'milk': 17,\n",
              " 'apple': 18,\n",
              " 'picked': 19,\n",
              " 'is': 20,\n",
              " 'up': 21,\n",
              " 'bedroom': 22,\n",
              " 'the': 23,\n",
              " '?': 24,\n",
              " 'back': 25,\n",
              " 'got': 26,\n",
              " 'john': 27,\n",
              " 'in': 28,\n",
              " 'discarded': 29,\n",
              " 'there': 30,\n",
              " 'dropped': 31,\n",
              " 'journeyed': 32,\n",
              " 'hallway': 33,\n",
              " 'office': 34,\n",
              " 'to': 35,\n",
              " 'bathroom': 36,\n",
              " 'sandra': 37}"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ],
      "source": [
        "tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "id": "cAwCchoaPHRa"
      },
      "outputs": [],
      "source": [
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answer_text = []\n",
        "for s,q,a in train_data:\n",
        "  train_story_text.append(s)\n",
        "  train_question_text.append(q)\n",
        "  train_answer_text.append(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "id": "tMcHehmXPxhb"
      },
      "outputs": [],
      "source": [
        "# train_story_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "4GXEG9b_P3hT"
      },
      "outputs": [],
      "source": [
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)\n",
        "# train_story_seq = np.array(train_story_seq)\n",
        "# train_story_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "id": "_g6BzHV6Sctc"
      },
      "outputs": [],
      "source": [
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=maxlen_stories,max_question_len=maxlen_question):\n",
        "    '''\n",
        "    OUTPUT:\n",
        "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
        "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
        "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
        "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
        "    '''\n",
        "    # X = STORIES\n",
        "    X = []\n",
        "    # Xq = QUERY/QUESTION\n",
        "    Xq = []\n",
        "    # Y = CORRECT ANSWER\n",
        "    Y = []\n",
        "\n",
        "\n",
        "    for story, query, answer in data:\n",
        "\n",
        "        # Grab the word index for every word in story\n",
        "        x = [word_index[word.lower()] for word in story]\n",
        "        xq = [word_index[word.lower()] for word in query]\n",
        "        y = np.zeros(len(word_index) + 1)\n",
        "        y[word_index[answer]] = 1\n",
        "\n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "\n",
        "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "h274ywkRY6S0"
      },
      "outputs": [],
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)\n",
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "4v8s72fsaMVz"
      },
      "outputs": [],
      "source": [
        "import keras.layers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Embedding,Input, Activation, Dense, Permute, Dropout,add, dot, concatenate,LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNVCEfUNeT4_",
        "outputId": "2664655c-a86f-485a-f0cc-c1a2ae176f97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 6) dtype=float32 (created by layer 'input_6')>"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ],
      "source": [
        "input_sequence = Input((maxlen_stories,))\n",
        "question_sequence = Input((maxlen_question,))\n",
        "question_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### input encoder M"
      ],
      "metadata": {
        "id": "Smh5NXventeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_len,output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.5))\n",
        "\n",
        "# This encoder will output:\n",
        "# (samples, story_maxlen, embedding_dim)"
      ],
      "metadata": {
        "id": "rcHDMBfUmPz9"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "e7_Cq4ZEn0GA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### input encoder C"
      ],
      "metadata": {
        "id": "eMGP8iEJn0p2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_len,output_dim=maxlen_question))\n",
        "input_encoder_c.add(Dropout(0.5))\n",
        "# output: (samples, story_maxlen, query_maxlen)"
      ],
      "metadata": {
        "id": "K3F8nKwnmjEg"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### question encoder\n"
      ],
      "metadata": {
        "id": "WrJZO5z6n5d_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_len,\n",
        "                               output_dim=64,\n",
        "                               input_length=maxlen_question))\n",
        "question_encoder.add(Dropout(0.5))\n",
        "# output: (samples, query_maxlen, embedding_dim)"
      ],
      "metadata": {
        "id": "dStoipFhnUAv"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode input sequence and questions (which are indices)\n",
        "# to sequences of dense vectors\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question_sequence)"
      ],
      "metadata": {
        "id": "qsyRNle0oCQm"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation('softmax')(match)"
      ],
      "metadata": {
        "id": "KyaYx0lxoYCW"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
      ],
      "metadata": {
        "id": "q1VnfAh_onKX"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate the match matrix with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])\n",
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_mlcg2novDS",
        "outputId": "f524f3f5-1beb-4f7a-c100-d8db8d16052f"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 6, 220) dtype=float32 (created by layer 'concatenate_2')>"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce with RNN (LSTM)\n",
        "answer = LSTM(32)(answer)  # (samples, 32)\n",
        "# Regularization with Dropout\n",
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_len)(answer)  # (samples, vocab_size)\n",
        "# probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)"
      ],
      "metadata": {
        "id": "tV2f9m1bo1Oa"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([input_sequence, question_sequence], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "cjQcVtLFo1s2"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVunDCx-pKY9",
        "outputId": "a1ea3648-df1c-420c-9cb9-8a1493d39257"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 156)]                0         []                            \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)        [(None, 6)]                  0         []                            \n",
            "                                                                                                  \n",
            " sequential_6 (Sequential)   (None, None, 64)             2432      ['input_5[0][0]']             \n",
            "                                                                                                  \n",
            " sequential_8 (Sequential)   (None, 6, 64)                2432      ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " dot_2 (Dot)                 (None, 156, 6)               0         ['sequential_6[0][0]',        \n",
            "                                                                     'sequential_8[0][0]']        \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 156, 6)               0         ['dot_2[0][0]']               \n",
            "                                                                                                  \n",
            " sequential_7 (Sequential)   (None, None, 6)              228       ['input_5[0][0]']             \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 156, 6)               0         ['activation_4[0][0]',        \n",
            "                                                                     'sequential_7[0][0]']        \n",
            "                                                                                                  \n",
            " permute_2 (Permute)         (None, 6, 156)               0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 6, 220)               0         ['permute_2[0][0]',           \n",
            " )                                                                   'sequential_8[0][0]']        \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               (None, 32)                   32384     ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)        (None, 32)                   0         ['lstm_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 38)                   1254      ['dropout_11[0][0]']          \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 38)                   0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 38730 (151.29 KB)\n",
            "Trainable params: 38730 (151.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=150,validation_data=([inputs_test, queries_test], answers_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNbqw6MOpkHK",
        "outputId": "a012c71a-2ac4-4ec9-b2c5-0a68b6a46856"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "313/313 [==============================] - 5s 10ms/step - loss: 0.8336 - accuracy: 0.5002 - val_loss: 0.6943 - val_accuracy: 0.5030\n",
            "Epoch 2/150\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.7011 - accuracy: 0.5080 - val_loss: 0.6949 - val_accuracy: 0.5030\n",
            "Epoch 3/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6966 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 4/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6961 - accuracy: 0.5043 - val_loss: 0.6950 - val_accuracy: 0.4970\n",
            "Epoch 5/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6965 - accuracy: 0.4961 - val_loss: 0.6947 - val_accuracy: 0.4970\n",
            "Epoch 6/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6950 - accuracy: 0.5091 - val_loss: 0.6947 - val_accuracy: 0.4970\n",
            "Epoch 7/150\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6963 - accuracy: 0.4929 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
            "Epoch 8/150\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.6956 - accuracy: 0.4977 - val_loss: 0.6939 - val_accuracy: 0.5030\n",
            "Epoch 9/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6949 - accuracy: 0.5006 - val_loss: 0.6945 - val_accuracy: 0.5030\n",
            "Epoch 10/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6956 - accuracy: 0.4947 - val_loss: 0.6994 - val_accuracy: 0.4970\n",
            "Epoch 11/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6956 - accuracy: 0.4984 - val_loss: 0.6950 - val_accuracy: 0.5030\n",
            "Epoch 12/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6951 - accuracy: 0.5008 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 13/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6954 - accuracy: 0.4964 - val_loss: 0.6935 - val_accuracy: 0.4970\n",
            "Epoch 14/150\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.6953 - accuracy: 0.4983 - val_loss: 0.6965 - val_accuracy: 0.5030\n",
            "Epoch 15/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6951 - accuracy: 0.5005 - val_loss: 0.6956 - val_accuracy: 0.4970\n",
            "Epoch 16/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6950 - accuracy: 0.5040 - val_loss: 0.6938 - val_accuracy: 0.5030\n",
            "Epoch 17/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6950 - accuracy: 0.5033 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
            "Epoch 18/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6953 - accuracy: 0.4936 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 19/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6952 - accuracy: 0.4975 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
            "Epoch 20/150\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.6946 - accuracy: 0.4987 - val_loss: 0.6937 - val_accuracy: 0.5030\n",
            "Epoch 21/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6952 - accuracy: 0.5008 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
            "Epoch 22/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6953 - accuracy: 0.5017 - val_loss: 0.6940 - val_accuracy: 0.4970\n",
            "Epoch 23/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6955 - accuracy: 0.4977 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
            "Epoch 24/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6951 - accuracy: 0.4994 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 25/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6951 - accuracy: 0.5064 - val_loss: 0.6948 - val_accuracy: 0.4970\n",
            "Epoch 26/150\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.6957 - accuracy: 0.4894 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 27/150\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6947 - accuracy: 0.5048 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 28/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6949 - accuracy: 0.5009 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
            "Epoch 29/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6950 - accuracy: 0.5033 - val_loss: 0.6943 - val_accuracy: 0.5030\n",
            "Epoch 30/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6954 - accuracy: 0.4936 - val_loss: 0.6959 - val_accuracy: 0.5030\n",
            "Epoch 31/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6950 - accuracy: 0.5016 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 32/150\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.6935 - accuracy: 0.5157 - val_loss: 0.6951 - val_accuracy: 0.4970\n",
            "Epoch 33/150\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6952 - accuracy: 0.4953 - val_loss: 0.6939 - val_accuracy: 0.5030\n",
            "Epoch 34/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6952 - accuracy: 0.4999 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 35/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6947 - accuracy: 0.5006 - val_loss: 0.6941 - val_accuracy: 0.4970\n",
            "Epoch 36/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6948 - accuracy: 0.5027 - val_loss: 0.6947 - val_accuracy: 0.4970\n",
            "Epoch 37/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6952 - accuracy: 0.4944 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
            "Epoch 38/150\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6952 - accuracy: 0.4943 - val_loss: 0.6963 - val_accuracy: 0.5030\n",
            "Epoch 39/150\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.6950 - accuracy: 0.4951 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
            "Epoch 40/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6950 - accuracy: 0.4938 - val_loss: 0.6942 - val_accuracy: 0.4970\n",
            "Epoch 41/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6945 - accuracy: 0.5089 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 42/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6950 - accuracy: 0.5024 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
            "Epoch 43/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6946 - accuracy: 0.5008 - val_loss: 0.6946 - val_accuracy: 0.4970\n",
            "Epoch 44/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6954 - accuracy: 0.4971 - val_loss: 0.6938 - val_accuracy: 0.4970\n",
            "Epoch 45/150\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.6948 - accuracy: 0.4977 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 46/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6953 - accuracy: 0.4921 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 47/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6946 - accuracy: 0.5016 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
            "Epoch 48/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6950 - accuracy: 0.5029 - val_loss: 0.6932 - val_accuracy: 0.4920\n",
            "Epoch 49/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6950 - accuracy: 0.4891 - val_loss: 0.6935 - val_accuracy: 0.4970\n",
            "Epoch 50/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6947 - accuracy: 0.5026 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
            "Epoch 51/150\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.6950 - accuracy: 0.4979 - val_loss: 0.6951 - val_accuracy: 0.4970\n",
            "Epoch 52/150\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6943 - accuracy: 0.5099 - val_loss: 0.6935 - val_accuracy: 0.4970\n",
            "Epoch 53/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6949 - accuracy: 0.4985 - val_loss: 0.6953 - val_accuracy: 0.4970\n",
            "Epoch 54/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6950 - accuracy: 0.4941 - val_loss: 0.6932 - val_accuracy: 0.4960\n",
            "Epoch 55/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6944 - accuracy: 0.5037 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 56/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6945 - accuracy: 0.4991 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
            "Epoch 57/150\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.6948 - accuracy: 0.4983 - val_loss: 0.6959 - val_accuracy: 0.4970\n",
            "Epoch 58/150\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6946 - accuracy: 0.4989 - val_loss: 0.6934 - val_accuracy: 0.4970\n",
            "Epoch 59/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6950 - accuracy: 0.4969 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
            "Epoch 60/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6946 - accuracy: 0.5070 - val_loss: 0.6932 - val_accuracy: 0.5050\n",
            "Epoch 61/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6949 - accuracy: 0.5010 - val_loss: 0.6950 - val_accuracy: 0.4970\n",
            "Epoch 62/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6948 - accuracy: 0.4969 - val_loss: 0.6933 - val_accuracy: 0.4920\n",
            "Epoch 63/150\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6948 - accuracy: 0.4968 - val_loss: 0.6944 - val_accuracy: 0.4970\n",
            "Epoch 64/150\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.6948 - accuracy: 0.4955 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 65/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6944 - accuracy: 0.5039 - val_loss: 0.6957 - val_accuracy: 0.5030\n",
            "Epoch 66/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6943 - accuracy: 0.5059 - val_loss: 0.6945 - val_accuracy: 0.5030\n",
            "Epoch 67/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6947 - accuracy: 0.4991 - val_loss: 0.6938 - val_accuracy: 0.4950\n",
            "Epoch 68/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6938 - accuracy: 0.5081 - val_loss: 0.6938 - val_accuracy: 0.4880\n",
            "Epoch 69/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6938 - accuracy: 0.5105 - val_loss: 0.6939 - val_accuracy: 0.5090\n",
            "Epoch 70/150\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.6943 - accuracy: 0.5081 - val_loss: 0.6941 - val_accuracy: 0.5020\n",
            "Epoch 71/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6940 - accuracy: 0.5096 - val_loss: 0.6943 - val_accuracy: 0.4930\n",
            "Epoch 72/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6932 - accuracy: 0.5148 - val_loss: 0.6973 - val_accuracy: 0.4950\n",
            "Epoch 73/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6948 - accuracy: 0.5040 - val_loss: 0.6942 - val_accuracy: 0.5030\n",
            "Epoch 74/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6935 - accuracy: 0.5089 - val_loss: 0.6940 - val_accuracy: 0.4880\n",
            "Epoch 75/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6944 - accuracy: 0.5090 - val_loss: 0.6938 - val_accuracy: 0.4930\n",
            "Epoch 76/150\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.6934 - accuracy: 0.5138 - val_loss: 0.6939 - val_accuracy: 0.5230\n",
            "Epoch 77/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6928 - accuracy: 0.5079 - val_loss: 0.6931 - val_accuracy: 0.5170\n",
            "Epoch 78/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6911 - accuracy: 0.5182 - val_loss: 0.6919 - val_accuracy: 0.5030\n",
            "Epoch 79/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6895 - accuracy: 0.5226 - val_loss: 0.6912 - val_accuracy: 0.5290\n",
            "Epoch 80/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6860 - accuracy: 0.5280 - val_loss: 0.6855 - val_accuracy: 0.5500\n",
            "Epoch 81/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6814 - accuracy: 0.5392 - val_loss: 0.6757 - val_accuracy: 0.6040\n",
            "Epoch 82/150\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.6759 - accuracy: 0.5552 - val_loss: 0.6662 - val_accuracy: 0.6320\n",
            "Epoch 83/150\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6716 - accuracy: 0.5659 - val_loss: 0.6586 - val_accuracy: 0.6440\n",
            "Epoch 84/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6687 - accuracy: 0.5739 - val_loss: 0.6517 - val_accuracy: 0.6480\n",
            "Epoch 85/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6605 - accuracy: 0.5861 - val_loss: 0.6412 - val_accuracy: 0.6530\n",
            "Epoch 86/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6585 - accuracy: 0.5925 - val_loss: 0.6389 - val_accuracy: 0.6550\n",
            "Epoch 87/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6535 - accuracy: 0.6072 - val_loss: 0.6290 - val_accuracy: 0.6730\n",
            "Epoch 88/150\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6462 - accuracy: 0.6264 - val_loss: 0.6199 - val_accuracy: 0.6920\n",
            "Epoch 89/150\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.6369 - accuracy: 0.6322 - val_loss: 0.6020 - val_accuracy: 0.6970\n",
            "Epoch 90/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6280 - accuracy: 0.6566 - val_loss: 0.5964 - val_accuracy: 0.7040\n",
            "Epoch 91/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6183 - accuracy: 0.6684 - val_loss: 0.5763 - val_accuracy: 0.7260\n",
            "Epoch 92/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6089 - accuracy: 0.6750 - val_loss: 0.5727 - val_accuracy: 0.7330\n",
            "Epoch 93/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6055 - accuracy: 0.6794 - val_loss: 0.5544 - val_accuracy: 0.7360\n",
            "Epoch 94/150\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.5905 - accuracy: 0.7012 - val_loss: 0.5508 - val_accuracy: 0.7450\n",
            "Epoch 95/150\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.5803 - accuracy: 0.7100 - val_loss: 0.5243 - val_accuracy: 0.7670\n",
            "Epoch 96/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.5664 - accuracy: 0.7174 - val_loss: 0.5144 - val_accuracy: 0.7660\n",
            "Epoch 97/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.5580 - accuracy: 0.7280 - val_loss: 0.5125 - val_accuracy: 0.7670\n",
            "Epoch 98/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.5528 - accuracy: 0.7277 - val_loss: 0.5220 - val_accuracy: 0.7750\n",
            "Epoch 99/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.5513 - accuracy: 0.7275 - val_loss: 0.4925 - val_accuracy: 0.7760\n",
            "Epoch 100/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.5388 - accuracy: 0.7398 - val_loss: 0.4997 - val_accuracy: 0.7650\n",
            "Epoch 101/150\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.5359 - accuracy: 0.7429 - val_loss: 0.4931 - val_accuracy: 0.7790\n",
            "Epoch 102/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.5194 - accuracy: 0.7576 - val_loss: 0.4755 - val_accuracy: 0.7830\n",
            "Epoch 103/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.5201 - accuracy: 0.7489 - val_loss: 0.4745 - val_accuracy: 0.7840\n",
            "Epoch 104/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.5090 - accuracy: 0.7626 - val_loss: 0.4887 - val_accuracy: 0.7810\n",
            "Epoch 105/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.5106 - accuracy: 0.7673 - val_loss: 0.4928 - val_accuracy: 0.7800\n",
            "Epoch 106/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.4908 - accuracy: 0.7740 - val_loss: 0.4650 - val_accuracy: 0.7870\n",
            "Epoch 107/150\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.4896 - accuracy: 0.7747 - val_loss: 0.4619 - val_accuracy: 0.7840\n",
            "Epoch 108/150\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.4777 - accuracy: 0.7818 - val_loss: 0.4386 - val_accuracy: 0.8040\n",
            "Epoch 109/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.4683 - accuracy: 0.7901 - val_loss: 0.4511 - val_accuracy: 0.8020\n",
            "Epoch 110/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.4665 - accuracy: 0.7901 - val_loss: 0.4473 - val_accuracy: 0.8080\n",
            "Epoch 111/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.4560 - accuracy: 0.7986 - val_loss: 0.4328 - val_accuracy: 0.8060\n",
            "Epoch 112/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.4399 - accuracy: 0.8069 - val_loss: 0.4302 - val_accuracy: 0.8080\n",
            "Epoch 113/150\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.4330 - accuracy: 0.8094 - val_loss: 0.4159 - val_accuracy: 0.8030\n",
            "Epoch 114/150\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.4250 - accuracy: 0.8133 - val_loss: 0.4352 - val_accuracy: 0.8020\n",
            "Epoch 115/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.4221 - accuracy: 0.8162 - val_loss: 0.4038 - val_accuracy: 0.8270\n",
            "Epoch 116/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.4151 - accuracy: 0.8181 - val_loss: 0.3944 - val_accuracy: 0.8230\n",
            "Epoch 117/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.4056 - accuracy: 0.8253 - val_loss: 0.4012 - val_accuracy: 0.8200\n",
            "Epoch 118/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3994 - accuracy: 0.8287 - val_loss: 0.4125 - val_accuracy: 0.8300\n",
            "Epoch 119/150\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.3957 - accuracy: 0.8303 - val_loss: 0.3949 - val_accuracy: 0.8420\n",
            "Epoch 120/150\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.3933 - accuracy: 0.8306 - val_loss: 0.3850 - val_accuracy: 0.8350\n",
            "Epoch 121/150\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3884 - accuracy: 0.8351 - val_loss: 0.3922 - val_accuracy: 0.8310\n",
            "Epoch 122/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3802 - accuracy: 0.8353 - val_loss: 0.3969 - val_accuracy: 0.8350\n",
            "Epoch 123/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3763 - accuracy: 0.8379 - val_loss: 0.3845 - val_accuracy: 0.8320\n",
            "Epoch 124/150\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3724 - accuracy: 0.8391 - val_loss: 0.3752 - val_accuracy: 0.8350\n",
            "Epoch 125/150\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3706 - accuracy: 0.8396 - val_loss: 0.3726 - val_accuracy: 0.8420\n",
            "Epoch 126/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3712 - accuracy: 0.8448 - val_loss: 0.3727 - val_accuracy: 0.8420\n",
            "Epoch 127/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3666 - accuracy: 0.8442 - val_loss: 0.3769 - val_accuracy: 0.8390\n",
            "Epoch 128/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3622 - accuracy: 0.8465 - val_loss: 0.3673 - val_accuracy: 0.8370\n",
            "Epoch 129/150\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3570 - accuracy: 0.8486 - val_loss: 0.3681 - val_accuracy: 0.8470\n",
            "Epoch 130/150\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3614 - accuracy: 0.8474 - val_loss: 0.3669 - val_accuracy: 0.8400\n",
            "Epoch 131/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3600 - accuracy: 0.8515 - val_loss: 0.3795 - val_accuracy: 0.8360\n",
            "Epoch 132/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3610 - accuracy: 0.8462 - val_loss: 0.3674 - val_accuracy: 0.8410\n",
            "Epoch 133/150\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3564 - accuracy: 0.8503 - val_loss: 0.3717 - val_accuracy: 0.8370\n",
            "Epoch 134/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3520 - accuracy: 0.8514 - val_loss: 0.3917 - val_accuracy: 0.8360\n",
            "Epoch 135/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3599 - accuracy: 0.8468 - val_loss: 0.3703 - val_accuracy: 0.8450\n",
            "Epoch 136/150\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.3505 - accuracy: 0.8516 - val_loss: 0.3739 - val_accuracy: 0.8410\n",
            "Epoch 137/150\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3490 - accuracy: 0.8456 - val_loss: 0.3613 - val_accuracy: 0.8390\n",
            "Epoch 138/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3442 - accuracy: 0.8531 - val_loss: 0.3712 - val_accuracy: 0.8350\n",
            "Epoch 139/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3469 - accuracy: 0.8548 - val_loss: 0.3684 - val_accuracy: 0.8450\n",
            "Epoch 140/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3436 - accuracy: 0.8531 - val_loss: 0.3735 - val_accuracy: 0.8340\n",
            "Epoch 141/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3410 - accuracy: 0.8545 - val_loss: 0.3712 - val_accuracy: 0.8300\n",
            "Epoch 142/150\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.3419 - accuracy: 0.8534 - val_loss: 0.3710 - val_accuracy: 0.8370\n",
            "Epoch 143/150\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3281 - accuracy: 0.8588 - val_loss: 0.3580 - val_accuracy: 0.8380\n",
            "Epoch 144/150\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3345 - accuracy: 0.8578 - val_loss: 0.3956 - val_accuracy: 0.8400\n",
            "Epoch 145/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3381 - accuracy: 0.8559 - val_loss: 0.3761 - val_accuracy: 0.8310\n",
            "Epoch 146/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3332 - accuracy: 0.8571 - val_loss: 0.3812 - val_accuracy: 0.8340\n",
            "Epoch 147/150\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3304 - accuracy: 0.8604 - val_loss: 0.3774 - val_accuracy: 0.8320\n",
            "Epoch 148/150\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.3300 - accuracy: 0.8591 - val_loss: 0.3698 - val_accuracy: 0.8360\n",
            "Epoch 149/150\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3255 - accuracy: 0.8609 - val_loss: 0.3755 - val_accuracy: 0.8370\n",
            "Epoch 150/150\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3306 - accuracy: 0.8565 - val_loss: 0.3683 - val_accuracy: 0.8350\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f2e62e86da0>"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'chatbot.h5'\n",
        "model.save(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZQvmx-Xp_5i",
        "outputId": "51b51521-49da-4721-871e-41fc151592c9"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(filename)\n",
        "pred_results = model.predict(([inputs_test, queries_test]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0McX4E5_qI3I",
        "outputId": "4a5efa5d-7584-4c22-e4c7-2b09cc06b81c"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "story =' '.join(word for word in test_data[1][0])\n",
        "print(story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hM4r81HTqapG",
        "outputId": "bb24a751-9150-4d06-8bce-bb8d423aec20"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mary got the milk there . John moved to the bedroom . Mary discarded the milk . John went to the garden .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = ' '.join(word for word in test_data[1][1])\n",
        "print(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2--gvqFZqkiB",
        "outputId": "33046c22-84ce-4c68-8554-a0cd69aefc44"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is John in the kitchen ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Answer is:\",test_data[1][2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRo3iI-dqkrS",
        "outputId": "bdaab672-3c52-4501-8199-71da5777c923"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer is: no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51u6iVm6qyUk",
        "outputId": "51cd7867-1360-4e26-e363-e079ccb56e38"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted answer is:  no\n",
            "Probability of certainty was:  0.98773766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
        "my_story.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVn69ZgjrY0_",
        "outputId": "d2c5aa99-5311-454e-f7c8-82c7c47a54fd"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John',\n",
              " 'left',\n",
              " 'the',\n",
              " 'kitchen',\n",
              " '.',\n",
              " 'Sandra',\n",
              " 'dropped',\n",
              " 'the',\n",
              " 'football',\n",
              " 'in',\n",
              " 'the',\n",
              " 'garden',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_question = \"is sandra in the kitchen ?\"\n",
        "my_question.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBjhHpf-rcHg",
        "outputId": "19cc148b-32c3-46e7-9b7d-359a162f5d4b"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['is', 'sandra', 'in', 'the', 'kitchen', '?']"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mydata = [(my_story.split(),my_question.split(),'yes')]"
      ],
      "metadata": {
        "id": "FcBPAmUKrnDy"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_story,my_ques,my_ans = vectorize_stories(mydata)"
      ],
      "metadata": {
        "id": "JeCYgPH2rtLu"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results = model.predict(([ my_story, my_ques]))\n",
        "pred_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QFrrFWbrzW-",
        "outputId": "c7786375-ebb0-4d0b-cc31-82d09cf50b4b"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.4625823e-07, 6.0958536e-07, 6.0558892e-07, 5.4668311e-07,\n",
              "        5.0562619e-07, 5.7854521e-07, 5.0225642e-02, 9.4975430e-01,\n",
              "        6.6211840e-07, 4.6306127e-07, 5.4344520e-07, 6.7925527e-07,\n",
              "        5.4317525e-07, 5.0117114e-07, 6.1868434e-07, 5.7458186e-07,\n",
              "        5.7907124e-07, 4.2912677e-07, 4.7670451e-07, 6.0468057e-07,\n",
              "        6.0906234e-07, 6.1060183e-07, 5.3535160e-07, 5.4721096e-07,\n",
              "        5.7368061e-07, 4.2825349e-07, 5.1121572e-07, 5.7979901e-07,\n",
              "        5.6752503e-07, 5.6164328e-07, 5.6442406e-07, 4.6170663e-07,\n",
              "        4.9580632e-07, 8.0467947e-07, 5.6998425e-07, 4.4022880e-07,\n",
              "        5.0185747e-07, 4.1981858e-07]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEJU9H5pr95H",
        "outputId": "36864a00-16b8-42bb-c5e9-1f2d707eb4b4"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted answer is:  no\n",
            "Probability of certainty was:  0.9497543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mdL8QUOXITR1"
      },
      "execution_count": 232,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}